\section{Introduction}


There is no doubt that eye-tracking is the next big leap for Virtual and Augmented reality (VR/AR) on their way towards mass market. The main reason for that is the number of opportunities it opens for significant improvement of the overall user experience.

First of all, human's eye-vision system is one of the main tool for the interaction with the surrounding environment, so eye-tracking introduces a new natural dimension for human-computer interaction (HCI) domain. This allows to use eye gaze information for foveated rendering - the approach of reallocating computational resources to the current subjects' fixation point which can be used to decrease the power consumption or preserve the same amount of it but improve the rendering quality  ~\cite{guenter2012foveated}. In addition to this, touch-less interaction allows building immerse virtual environment that is responsive for user's gaze or even might be the only possible way to deal with a machine for disabled people. 

Secondly, the specific traits of each subject's oculomotor system, eye shape, periocular features etc. were proved to have a great potential for biometrics and health assessment applications. In the lab environment, it's possible to build biometrics system with the equal-error rate (EER) of 3\% which is on par with a fingerprint sensor [?]. The main advantage of such system that there is no known way to spoof it which is not the case for a fingerprint sensor or face recognition system. From the health assessment point of view, it is shown that such disease as schizophrenia, mild traumatic brain injury, ... can be identified from the special features extracted from the subject's eye signal [?].  

As for the end of 2018, the current state of eye-tracking in VR can be seen in devices like FOVE VR and HTC Vive with third-party add-ons from SMI or PupilLabs. None of them are wireless and all of them operates using Video-based oculography (VOG) sensors . For lab-oriented equipment this technology allows to have very high sampling frequency up to 2000 Hz and spatial scores in terms of degrees of visual angle lower than 0.5\textdegree{} and 0.05\textdegree{} for accuracy and precision respectively (EyeLink 1000 Plus, ~\cite{EyeLink1000P}). Due to restrictions of the VR headset form factor, for devices listed above this numbers are quite lower: up to 250 Hz sampling frequency and the spatial accuracy less than 1.0\textdegree{}. Using VOG leads to huge total power consumption of sensor system itself plus the hardware dedicated for real-time processing of captured eye images. That fact is the main restriction that blocks using      

This study aims on eye-tracking sensor that 

\section{Prior work}



\begin{acks}
  The authors would like to thank Dr. Yuhua Li for providing the
  MATLAB code of the \textit{BEPS} method.

  The authors would also like to thank the anonymous referees for
  their valuable comments and helpful suggestions. The work is
  supported by the \grantsponsor{GS501100001809}{National Natural
    Science Foundation of
    China}{http://dx.doi.org/10.13039/501100001809} under Grant
  No.:~\grantnum{GS501100001809}{61273304}
  and~\grantnum[http://www.nnsf.cn/youngscientists]{GS501100001809}{Young
    Scientists' Support Program}.

\end{acks}
